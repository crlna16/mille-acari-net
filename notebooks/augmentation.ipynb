{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "from torchvision import tv_tensors\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../data/images/IMG_20241207_163835.jpg'\n",
    "label_path = image_path.replace('images', 'labels').replace('.jpg', '.txt')\n",
    "image = Image.open(image_path)\n",
    "\n",
    "yolo_boxes = []\n",
    "yolo_classes = []\n",
    "with open(label_path, 'r') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "        yolo_boxes.append([x_center, y_center, width, height])\n",
    "        yolo_classes.append([class_id])\n",
    "        line = f.readline()\n",
    "\n",
    "W, H = image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_image = torch.from_numpy(np.array(image).transpose(2, 0, 1))\n",
    "torch_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_boxes = torch.from_numpy(np.array(yolo_boxes).copy())\n",
    "tv_boxes[:, [0, 2]] *= W\n",
    "tv_boxes[:, [1, 3]] *= H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_boxes_xyxy = box_convert(tv_boxes, in_fmt='xywh', out_fmt='xyxy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbb = draw_bounding_boxes(torch_image, tv_boxes_xyxy, labels=None, colors='red', fill=True, width=10)\n",
    "plt.imshow(dbb.numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.RandomIoUCrop(min_scale=0.0001),\n",
    "    v2.Resize((512, 512)),\n",
    "    v2.RandomHorizontalFlip(0.5),\n",
    "    v2.RandomVerticalFlip(0.5),\n",
    "    v2.ColorJitter(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvt_image = tv_tensors.Image(torch_image)\n",
    "tvt_boxes = tv_tensors.BoundingBoxes(tv_boxes, format='XYWH', canvas_size=torch_image.shape[-2:], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafo_image, trafo_boxes = transform(tvt_image, tvt_boxes)\n",
    "sane_boxes = v2.SanitizeBoundingBoxes()({'labels':trafo_boxes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafo_boxes_xyxy = box_convert(sane_boxes['labels'], in_fmt='xywh', out_fmt='xyxy')\n",
    "dbb = draw_bounding_boxes(trafo_image, trafo_boxes_xyxy, labels=None, colors='red', fill=True, width=10)\n",
    "plt.imshow(dbb.numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
